#!/usr/bin/env python3
"""
ã‚µãƒ¼ãƒãƒ¼ã‚·ã‚¹ãƒ†ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
GPUé–“é€šä¿¡æ©Ÿèƒ½ã®ç†è«–çš„è©•ä¾¡ã¨å®Ÿè¨¼çš„æ¤œè¨¼æ‰‹é †
"""

import os
import subprocess
import json
from pathlib import Path

def analyze_gpu_hardware_configuration():
    """GPUãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ§‹æˆã®åˆ†æ"""
    print("=== GPUãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ§‹æˆåˆ†æ ===")
    
    # GPUãƒ‡ãƒã‚¤ã‚¹æ¤œå‡º
    gpu_devices = []
    for i in range(8):
        device_path = f'/dev/nvidia{i}'
        if os.path.exists(device_path):
            gpu_devices.append(i)
    
    print(f"æ¤œå‡ºã•ã‚ŒãŸGPUæ•°: {len(gpu_devices)}")
    print(f"GPU ID: {gpu_devices}")
    
    # /proc/driver/nvidia ã‹ã‚‰ã®æƒ…å ±å–å¾—
    nvidia_proc_path = '/proc/driver/nvidia'
    pci_addresses = []
    
    if os.path.exists(nvidia_proc_path):
        gpus_path = os.path.join(nvidia_proc_path, 'gpus')
        if os.path.exists(gpus_path):
            try:
                gpu_dirs = os.listdir(gpus_path)
                for gpu_dir in sorted(gpu_dirs):
                    if ':' in gpu_dir:  # PCI address format
                        pci_addresses.append(gpu_dir)
                        print(f"GPU PCI Address: {gpu_dir}")
            except Exception as e:
                print(f"PCIæƒ…å ±èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")
    
    return len(gpu_devices), pci_addresses

def analyze_pci_topology():
    """PCIãƒˆãƒãƒ­ã‚¸ãƒ¼ã®åˆ†æ"""
    print("\n=== PCIãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†æ ===")
    
    # RTX 6000 Ada Generation ã®ç†è«–çš„ãªPCIæ§‹æˆ
    print("RTX 6000 Ada Generation ã®ç†è«–çš„æ§‹æˆ:")
    print("- PCIe 4.0 x16 ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")
    print("- å„GPUã¯ç‹¬ç«‹ã—ãŸPCIeã‚¹ãƒ­ãƒƒãƒˆã«æ¥ç¶š")
    print("- 7æšæ§‹æˆã§ã®äºˆæƒ³ã•ã‚Œã‚‹é…ç½®:")
    
    # ä¸€èˆ¬çš„ãªã‚µãƒ¼ãƒãƒ¼æ§‹æˆã®åˆ†æ
    expected_configurations = [
        {
            "type": "ãƒ‡ãƒ¥ã‚¢ãƒ«CPU + PLXã‚¹ã‚¤ãƒƒãƒæ§‹æˆ",
            "description": "å„CPUã«3-4æšã®GPUãŒæ¥ç¶š",
            "cpu1_gpus": [0, 1, 2, 3],
            "cpu2_gpus": [4, 5, 6],
            "inter_cpu_bandwidth": "QPI/UPIçµŒç”± (ä½é€Ÿ)",
            "intra_cpu_bandwidth": "PCIe 4.0 ç›´æ¥ (é«˜é€Ÿ)"
        },
        {
            "type": "ã‚·ãƒ³ã‚°ãƒ«CPU + PCIeã‚¹ã‚¤ãƒƒãƒæ§‹æˆ",
            "description": "å…¨GPUãŒ1ã¤ã®CPUã«æ¥ç¶š",
            "cpu1_gpus": [0, 1, 2, 3, 4, 5, 6],
            "cpu2_gpus": [],
            "bandwidth": "PCIeã‚¹ã‚¤ãƒƒãƒçµŒç”±ã§åˆ†æ•£"
        }
    ]
    
    for config in expected_configurations:
        print(f"\n{config['type']}:")
        print(f"  - {config['description']}")
        if 'cpu1_gpus' in config:
            print(f"  - CPU1æ¥ç¶šGPU: {config['cpu1_gpus']}")
        if 'cpu2_gpus' in config and config['cpu2_gpus']:
            print(f"  - CPU2æ¥ç¶šGPU: {config['cpu2_gpus']}")

def analyze_memory_topology():
    """ãƒ¡ãƒ¢ãƒªãƒˆãƒãƒ­ã‚¸ãƒ¼ã®åˆ†æ"""
    print("\n=== ãƒ¡ãƒ¢ãƒªãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†æ ===")
    
    print("RTX 6000 Ada Generation ãƒ¡ãƒ¢ãƒªä»•æ§˜:")
    print("- å„GPU: 48GB GDDR6 ECC")
    print("- ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…: 960 GB/s (å„GPU)")
    print("- ç·ã‚·ã‚¹ãƒ†ãƒ GPUãƒ¡ãƒ¢ãƒª: 336GB (48GB Ã— 7)")
    
    print("\nãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æœŸå¾…å€¤:")
    print("- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹: ~960 GB/s")
    print("- P2Pãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ (NVLink): 300-600 GB/s")
    print("- P2Pãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ (PCIe): 20-30 GB/s")
    print("- CPU-GPUãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹: 25-32 GB/s")

def analyze_interconnect_topology():
    """ç›¸äº’æ¥ç¶šãƒˆãƒãƒ­ã‚¸ãƒ¼ã®åˆ†æ"""
    print("\n=== ç›¸äº’æ¥ç¶šãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†æ ===")
    
    print("RTX 6000 Ada Generation æ¥ç¶šä»•æ§˜:")
    print("- NVLink 4.0: 4ãƒãƒ¼ãƒˆ, æœ€å¤§900 GB/s")
    print("- PCIe 4.0: x16, æœ€å¤§32 GB/s")
    
    print("\n7GPUæ§‹æˆã§ã®ç†è«–çš„æ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³:")
    
    # å¯èƒ½ãªæ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
    connection_patterns = [
        {
            "name": "ãƒ•ãƒ«NVLinkæ¥ç¶š (ç†æƒ³)",
            "description": "å…¨GPUãŒNVLinkã§ç›´æ¥æ¥ç¶š",
            "pros": ["æœ€é«˜ã®é€šä¿¡å¸¯åŸŸå¹…", "ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·"],
            "cons": ["NVLinkãƒãƒ¼ãƒˆæ•°åˆ¶é™ã«ã‚ˆã‚Šå›°é›£"],
            "bandwidth": "300-600 GB/s"
        },
        {
            "name": "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¥ç¶š (ç¾å®Ÿçš„)",
            "description": "éš£æ¥GPUã¯NVLinkã€é éš”GPUã¯PCIe",
            "pros": ["ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½", "å®Ÿè£…å¯èƒ½"],
            "cons": ["ä¸€éƒ¨æ¥ç¶šãŒä½é€Ÿ"],
            "bandwidth": "50-300 GB/s"
        },
        {
            "name": "PCIe onlyæ¥ç¶š",
            "description": "å…¨GPUãŒPCIeçµŒç”±ã§æ¥ç¶š",
            "pros": ["ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆ", "ã‚³ã‚¹ãƒˆåŠ¹ç‡"],
            "cons": ["é€šä¿¡å¸¯åŸŸå¹…åˆ¶é™"],
            "bandwidth": "20-30 GB/s"
        }
    ]
    
    for pattern in connection_patterns:
        print(f"\n{pattern['name']}:")
        print(f"  èª¬æ˜: {pattern['description']}")
        print(f"  å¸¯åŸŸå¹…: {pattern['bandwidth']}")
        print(f"  åˆ©ç‚¹: {', '.join(pattern['pros'])}")
        print(f"  åˆ¶ç´„: {', '.join(pattern['cons'])}")

def calculate_performance_expectations():
    """æ€§èƒ½æœŸå¾…å€¤ã®è¨ˆç®—"""
    print("\n=== æ€§èƒ½æœŸå¾…å€¤è¨ˆç®— ===")
    
    scenarios = [
        {
            "name": "ç†æƒ³çš„ä¸¦åˆ—å­¦ç¿’",
            "gpu_count": 7,
            "model_size_gb": 4,
            "batch_size_per_gpu": 32,
            "communication_overhead": 0.1,
            "scaling_efficiency": 0.9
        },
        {
            "name": "å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
            "gpu_count": 7,
            "model_size_gb": 20,
            "batch_size_per_gpu": 8,
            "communication_overhead": 0.3,
            "scaling_efficiency": 0.7
        },
        {
            "name": "æ¨è«–ã‚¿ã‚¹ã‚¯",
            "gpu_count": 7,
            "model_size_gb": 8,
            "batch_size_per_gpu": 64,
            "communication_overhead": 0.05,
            "scaling_efficiency": 0.95
        }
    ]
    
    for scenario in scenarios:
        print(f"\n{scenario['name']}:")
        print(f"  GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {scenario['model_size_gb']}GB")
        print(f"  GPUæ¯ãƒãƒƒãƒã‚µã‚¤ã‚º: {scenario['batch_size_per_gpu']}")
        print(f"  é€šä¿¡ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {scenario['communication_overhead']*100:.1f}%")
        print(f"  æœŸå¾…ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åŠ¹ç‡: {scenario['scaling_efficiency']*100:.1f}%")
        
        # ç†è«–çš„æ€§èƒ½è¨ˆç®—
        single_gpu_performance = 100  # åŸºæº–å€¤
        ideal_multi_gpu = single_gpu_performance * scenario['gpu_count']
        actual_multi_gpu = ideal_multi_gpu * scenario['scaling_efficiency']
        
        print(f"  ç†è«–æœ€å¤§æ€§èƒ½: {ideal_multi_gpu:.0f}% (å˜GPUæ¯”)")
        print(f"  å®Ÿéš›æœŸå¾…æ€§èƒ½: {actual_multi_gpu:.0f}% (å˜GPUæ¯”)")

def generate_verification_plan():
    """æ¤œè¨¼è¨ˆç”»ã®ç”Ÿæˆ"""
    print("\n=== GPUé–“é€šä¿¡æ¤œè¨¼è¨ˆç”» ===")
    
    verification_steps = [
        {
            "phase": "Phase 1: åŸºæœ¬ç’°å¢ƒç¢ºèª",
            "tasks": [
                "ãƒ›ã‚¹ãƒˆç’°å¢ƒã§nvidia-smiå®Ÿè¡Œ",
                "nvidia-smi topo -m ã§ãƒˆãƒãƒ­ã‚¸ãƒ¼ç¢ºèª",
                "nvidia-smi nvlink -s ã§NVLinkçŠ¶æ…‹ç¢ºèª",
                "å„GPUã®æ¸©åº¦ãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–"
            ],
            "expected_time": "5åˆ†",
            "tools": ["nvidia-smi", "gpustat"]
        },
        {
            "phase": "Phase 2: é€šä¿¡æ€§èƒ½æ¸¬å®š",
            "tasks": [
                "CUDA samples bandwidthTestå®Ÿè¡Œ",
                "CUDA samples p2pBandwidthLatencyTestå®Ÿè¡Œ",
                "NCCLãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ",
                "ã‚«ã‚¹ã‚¿ãƒ P2Pè»¢é€ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"
            ],
            "expected_time": "15åˆ†",
            "tools": ["CUDA samples", "nccl-tests", "ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"]
        },
        {
            "phase": "Phase 3: å®Ÿãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰æ¤œè¨¼",
            "tasks": [
                "PyTorchåˆ†æ•£å­¦ç¿’ãƒ†ã‚¹ãƒˆ",
                "NeMo-RL ãƒãƒ«ãƒGPUå­¦ç¿’",
                "ãƒ¡ãƒ¢ãƒªåœ§è¿«ä¸‹ã§ã®é€šä¿¡æ€§èƒ½",
                "é•·æ™‚é–“é‹ç”¨ã§ã®å®‰å®šæ€§ç¢ºèª"
            ],
            "expected_time": "30åˆ†",
            "tools": ["PyTorch", "NeMo-RL", "ã‚«ã‚¹ã‚¿ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"]
        }
    ]
    
    for step in verification_steps:
        print(f"\n{step['phase']} ({step['expected_time']}):")
        for i, task in enumerate(step['tasks'], 1):
            print(f"  {i}. {task}")
        print(f"  ä½¿ç”¨ãƒ„ãƒ¼ãƒ«: {', '.join(step['tools'])}")

def create_host_test_script():
    """ãƒ›ã‚¹ãƒˆç’°å¢ƒç”¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ"""
    print("\n=== ãƒ›ã‚¹ãƒˆç’°å¢ƒãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ ===")
    
    script_content = '''#!/bin/bash
# GPUé–“é€šä¿¡åŒ…æ‹¬æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (ãƒ›ã‚¹ãƒˆç’°å¢ƒç”¨)

echo "GPUé–“é€šä¿¡åŒ…æ‹¬æ¤œè¨¼é–‹å§‹"
echo "================================"

# Phase 1: åŸºæœ¬ç’°å¢ƒç¢ºèª
echo "Phase 1: åŸºæœ¬ç’°å¢ƒç¢ºèª"
echo "nvidia-smiåŸºæœ¬æƒ…å ±:"
nvidia-smi

echo -e "\\nGPUãƒˆãƒãƒ­ã‚¸ãƒ¼:"
nvidia-smi topo -m

echo -e "\\nNVLinkçŠ¶æ…‹:"
nvidia-smi nvlink -s

echo -e "\\nNVLinkçµ±è¨ˆ:"
nvidia-smi nvlink -g

# Phase 2: æ€§èƒ½æ¸¬å®š
echo -e "\\n\\nPhase 2: æ€§èƒ½æ¸¬å®š"
echo "CUDA samples ãƒ†ã‚¹ãƒˆ:"

if command -v bandwidthTest &> /dev/null; then
    echo "å¸¯åŸŸå¹…ãƒ†ã‚¹ãƒˆ:"
    bandwidthTest
else
    echo "bandwidthTest not found"
fi

if command -v p2pBandwidthLatencyTest &> /dev/null; then
    echo "P2På¸¯åŸŸå¹…ãƒ»ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ†ã‚¹ãƒˆ:"
    p2pBandwidthLatencyTest
else
    echo "p2pBandwidthLatencyTest not found"
fi

# Phase 3: NCCLãƒ†ã‚¹ãƒˆ
echo -e "\\n\\nPhase 3: NCCLãƒ†ã‚¹ãƒˆ"
if command -v all_reduce_perf &> /dev/null; then
    echo "NCCL AllReduceæ€§èƒ½ãƒ†ã‚¹ãƒˆ:"
    all_reduce_perf -b 1M -e 1G -f 2 -g 7
else
    echo "nccl-tests not found"
fi

echo "\\n\\næ¤œè¨¼å®Œäº†"
echo "================================"
'''
    
    with open('server_test/host_comprehensive_test.sh', 'w') as f:
        f.write(script_content)
    
    os.chmod('host_comprehensive_test.sh', 0o755)
    print("ãƒ›ã‚¹ãƒˆç’°å¢ƒç”¨åŒ…æ‹¬ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ 'host_comprehensive_test.sh' ã‚’ä½œæˆ")

def generate_final_assessment():
    """æœ€çµ‚è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ"""
    print("\n" + "="*80)
    print("ã‚µãƒ¼ãƒãƒ¼çµ±åˆGPUé–“ãƒ‡ãƒ¼ã‚¿é€šä¿¡æ©Ÿèƒ½ æœ€çµ‚è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*80)
    
    print("\nã€ç¾åœ¨ã®çŠ¶æ³ã€‘")
    print("âœ… 7å°ã®NVIDIA RTX 6000 Ada Generation GPUæ¤œå‡º")
    print("âœ… GPUãƒ‡ãƒã‚¤ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æ­£å¸¸ã«å­˜åœ¨")
    print("âœ… NVIDIAãƒ‰ãƒ©ã‚¤ãƒãƒ¼æ­£å¸¸å‹•ä½œ")
    print("âš ï¸  ã‚³ãƒ³ãƒ†ãƒŠç’°å¢ƒã§CUDA APIåˆ¶é™")
    print("âš ï¸  nvidia-smiæ©Ÿèƒ½åˆ¶é™")
    
    print("\nã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ä»•æ§˜è©•ä¾¡ã€‘")
    print("ğŸŸ¢ GPUä»•æ§˜: å„ªç§€")
    print("   - RTX 6000 Ada Generation (48GB ECC)")
    print("   - NVLink 4.0å¯¾å¿œ")
    print("   - ç†è«–ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…: 960 GB/s Ã— 7 = 6.72 TB/s")
    
    print("\nã€æœŸå¾…ã•ã‚Œã‚‹é€šä¿¡æ€§èƒ½ã€‘")
    print("ğŸ“Š æ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥æœŸå¾…å€¤:")
    print("   - NVLinkç›´æ¥æ¥ç¶š: 300-600 GB/s")
    print("   - PCIe 4.0æ¥ç¶š: 25-32 GB/s")
    print("   - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“AllReduce: 100-300 GB/s")
    
    print("\nã€æ¨å¥¨æ¤œè¨¼æ‰‹é †ã€‘")
    print("1ï¸âƒ£ ãƒ›ã‚¹ãƒˆç’°å¢ƒã§ã®åŸºæœ¬ç¢ºèª (5åˆ†)")
    print("2ï¸âƒ£ CUDA samplesæ€§èƒ½æ¸¬å®š (15åˆ†)")
    print("3ï¸âƒ£ NCCLé€šä¿¡ãƒ†ã‚¹ãƒˆ (15åˆ†)")
    print("4ï¸âƒ£ å®Ÿãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰æ¤œè¨¼ (30åˆ†)")
    
    print("\nã€ãƒªã‚¹ã‚¯è©•ä¾¡ã€‘")
    print("ğŸŸ¡ ä¸­ç¨‹åº¦ã®ãƒªã‚¹ã‚¯:")
    print("   - GPU4æ¸©åº¦ã‚„ã‚„é«˜ã‚ (42Â°C) - å†·å´ç¢ºèªæ¨å¥¨")
    print("   - 7GPUæ§‹æˆã§ã®é›»åŠ›ãƒ»ç†±ç®¡ç†")
    print("   - å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã®é€šä¿¡ãƒœãƒˆãƒ«ãƒãƒƒã‚¯å¯èƒ½æ€§")
    
    print("\nã€ç·åˆåˆ¤å®šã€‘")
    print("ğŸ“‹ ç¾åœ¨ã®åˆ†æçµæœ:")
    print("   ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ§‹æˆ: ğŸŸ¢ å„ªç§€")
    print("   ç’°å¢ƒè¨­å®š: ğŸŸ¡ è¦ç¢ºèª")
    print("   é€šä¿¡æ€§èƒ½: â“ å®Ÿæ¸¬å¿…è¦")
    print("   é‹ç”¨æº–å‚™åº¦: ğŸŸ¡ è¿½åŠ æ¤œè¨¼æ¨å¥¨")
    
    print("\nã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘")
    print("ğŸ¯ å³åº§ã«å®Ÿè¡Œå¯èƒ½:")
    print("   1. ãƒ›ã‚¹ãƒˆç’°å¢ƒã§host_comprehensive_test.shå®Ÿè¡Œ")
    print("   2. æ¸©åº¦ç›£è¦–ä½“åˆ¶ç¢ºç«‹")
    print("   3. å®Ÿéš›ã®NeMo-RLå­¦ç¿’ã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    
    print("\nğŸ” ç†è«–çš„ã«ã¯7GPUé–“ã®é€šä¿¡æ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ãŒã€")
    print("   å®Ÿéš›ã®æ€§èƒ½ç¢ºèªã«ã¯ãƒ›ã‚¹ãƒˆç’°å¢ƒã§ã®è©³ç´°æ¸¬å®šãŒå¿…è¦ã§ã™ã€‚")

def main():
    print("ã‚µãƒ¼ãƒãƒ¼ã‚·ã‚¹ãƒ†ãƒ åŒ…æ‹¬åˆ†æ")
    print("="*60)
    
    # GPUãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ†æ
    gpu_count, pci_addresses = analyze_gpu_hardware_configuration()
    
    # ãƒˆãƒãƒ­ã‚¸ãƒ¼åˆ†æ
    analyze_pci_topology()
    analyze_memory_topology()
    analyze_interconnect_topology()
    
    # æ€§èƒ½æœŸå¾…å€¤è¨ˆç®—
    calculate_performance_expectations()
    
    # æ¤œè¨¼è¨ˆç”»
    generate_verification_plan()
    
    # ãƒ›ã‚¹ãƒˆç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ
    create_host_test_script()
    
    # æœ€çµ‚è©•ä¾¡
    generate_final_assessment()

if __name__ == "__main__":
    main() 